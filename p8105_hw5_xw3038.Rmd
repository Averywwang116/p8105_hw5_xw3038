---
title: "p8105_hw5_xw3038"
author: "Avery Wang"
date: "2024-11-14"
output: github_document
---

```{r}
library(tidyverse)
library(rvest)
library(readr)
library(purrr)
library(tidyr)
library(broom)

set.seed(1)

```

## Problem 1

```{r}
#function for finding the duplicate
check_duplicate_birthday=function(n){
  birthdays = sample(1:365, n, replace =TRUE)
  #check if they are duplicated
  if(length(birthdays)==length(unique(birthdays))){
    return(FALSE)
  }else{
    return(TRUE)
  }
  
}


```

```{r}
probability_calculation=
  expand_grid(
    #sample size from 2 to 50
    sample_size=2:50,
    iter=1:10000) |>
  mutate(
    #using map function
    duplicate_df=map(sample_size,check_duplicate_birthday)
  )|> 
  #unnest
  unnest(duplicate_df) |>
  group_by(sample_size)|>
  summarize(probability = mean(duplicate_df))
probability_calculation
```
```{r}
#plot the probability
probability_calculation|>
  ggplot(aes(x=sample_size,y=probability))+
  geom_line() +
  geom_point() +
  labs(
    x = "Group Size",
    y = "Probability of Shared Birthday",
    title = "Probability of At Least Two People Sharing a Birthday"
  ) +
  theme_minimal()
```

With the group size getting larger, the probability that at least two people in the group share the same birthday also increases

# Problem 2
```{r}
# make simulation
simulation_ttest=function(mu,n = 30,sigma = 5,alpha=0.05){
  x =rnorm(n, mean = mu, sd = sigma)
  t_test =t.test(x, mu=0)
  tidy_test=broom::tidy(t_test)
  tibble(
      mu_hat = tidy_test$estimate,
      p_value = tidy_test$p.value
    )
}
#for mu is 0
ttest_df_0=expand_grid(dataset=1: 5000,mu=0)|> 
  mutate(
    estimate_df = map_dfr(mu, simulation_ttest)
  ) |> 
  unnest(estimate_df)

# for the other case
ttest_df_others=expand_grid(dataset=1: 5000,mu=1:6)|> 
  mutate(
    estimate_df = map_dfr(mu, simulation_ttest)
  ) |> 
  unnest(estimate_df)

```

```{r}
#combine in order to plot
combined_df=bind_rows(ttest_df_0,ttest_df_others)
```

```{r}
#proportion of times rejected
combined_df=combined_df |>
  mutate(
    rejection=if_else(p_value<0.05,TRUE,FALSE)
  )

#group by mu and then plot
combined_df|> group_by(mu)|>
  summarize(proportion_rejection=mean(rejection)) |>
  ggplot(aes(x=mu,y=proportion_rejection))+
  geom_line() +
  geom_point() +
  labs(
    x = "mu",
    y = "power of test",
    title = "Proportion of Times Null was Rejected with different mu"
  ) +
  theme_minimal()

```


```{r}
combined_df|> group_by(mu)|>
  summarize(
    all_data= mean(mu_hat),
    reject_null = mean(mu_hat[p_value < 0.05])
  )|>
  pivot_longer(
    cols = c(all_data, reject_null),
    names_to = "estimate_type",
    values_to = "estimate"
  ) |>
  ggplot(aes(x = mu, y = estimate, color = estimate_type)) +
  geom_line() +
  geom_point() +
  labs(
    x = "Mu",
    y = "Average Estimate",
    title = "Average Estimate of estimate for All and Rejected Null",
    color = "Estimate Type"
  ) +
  theme_minimal()
  
```

the sample average of $\hat{\mu}$ for which the null hypothesis was rejected is not approximately equal to the true value of $\mu$. The possible reason is that samples with higher average estimate are more likely to have statistically significant results, and thus more likely to reject the null hypothesis.

